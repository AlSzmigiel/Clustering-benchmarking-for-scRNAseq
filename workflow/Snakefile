import sys
sys.path.append("workflow/scripts")
from itertools import product
import glob
import os
workflow.source_path("scripts/parse_config.py")
from parse_config import PrepConfig
configfile: "config/config.yaml"


cfg = PrepConfig(config)




def get_all_outputs(cfg):
    output_snakemake = []
    for dataset in cfg.get_subdata_names():
        dataset_file = os.path.join("results","benchmark_analysis", "processed_normalized_data", f"{dataset}.h5ad")
        if os.path.isfile(dataset_file):
            wildcards = cfg.get_possible_output(dataset)
            expanded_outputs = expand(
                "results/benchmark_analysis/evaluation/{dataset}/{clust_method}/{graph_method}/{sim_measure}/{neighbors}k.summary.txt",
                **wildcards
            )
            output_snakemake.extend(expanded_outputs)
        else:
            continue
    return output_snakemake

include:'rules/get_benchmark_datasets.smk'
include: 'rules/mitigate_bias_silver_standard.smk'
include: 'rules/benchmark_preprocessing.smk'
include: 'rules/benchmark_pairwise_similarity.smk'
include: 'rules/benchmark_graph_construction.smk'
include: 'rules/benchmark_clustering.smk'
include: 'rules/benchmark_evaluate.smk'
    

rule all:
    input:
        expand("data/processed_adata/{dataset}.h5ad", dataset=cfg.get_subdata_names()),
        expand("data/enhanced_silver_standard/{dataset}-new_lab.h5ad", dataset=cfg.get_silver_standard()),
        expand("results/benchmark_analysis/processed_normalized_data/{dataset}.h5ad",dataset=cfg.get_subdata_names()),
        get_all_outputs(cfg)

